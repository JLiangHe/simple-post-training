_wandb:
    value:
        cli_version: 0.21.0
        e:
            5zhpe6z6ijzaa17aujca5y8nixd2c31e:
                args:
                    - data.train_files=/gpfs/radev/home/jh3439/project/simple-post-training/lm_sft/data/processed_data/train.parquet
                    - data.val_files=/gpfs/radev/home/jh3439/project/simple-post-training/lm_sft/data/processed_data/test.parquet
                    - data.multiturn.enable=true
                    - data.multiturn.messages_key=messages
                    - data.micro_batch_size=1
                    - data.train_batch_size=128
                    - data.max_length=2048
                    - data.truncation=right
                    - model.partial_pretrain=/gpfs/radev/home/jh3439/project/simple-post-training/lm_sft/data/processed_models/meta-llama_Llama-3.1-8B
                    - model.enable_gradient_checkpointing=true
                    - model.fsdp_config.cpu_offload=false
                    - model.fsdp_config.offload_params=false
                    - model.fsdp_config.model_dtype=bfloat16
                    - trainer.default_local_dir=/gpfs/radev/home/jh3439/project/simple-post-training/lm_sft/results/meta-llama_Llama-3.1-8B
                    - trainer.project_name=verl-post-training-pipeline-sft
                    - trainer.experiment_name=sft-llama-3.1-8b-multiturn
                    - trainer.default_hdfs_dir=null
                    - ulysses_sequence_parallel_size=1
                    - use_remove_padding=true
                cpu_count: 32
                cpu_count_logical: 32
                cudaVersion: "12.8"
                disk:
                    /:
                        total: "540947222528"
                        used: "14659584"
                email: jlianghe@outlook.com
                executable: /gpfs/radev/home/jh3439/.conda/envs/llm_base/bin/python3.10
                git:
                    commit: 5edb06e3e73aff7bf6c107ff4f426e8fcef77eef
                    remote: https://github.com/JLiangHe/simple-post-training.git
                gpu: NVIDIA A100 80GB PCIe
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 6912
                      memoryTotal: "85899345920"
                      name: NVIDIA A100 80GB PCIe
                      uuid: GPU-c34a41e7-f31f-192f-8d3c-4bdcfb9b8489
                host: r4519u16n01.misha.ycrc.yale.edu
                memory:
                    total: "1081894449152"
                os: Linux-4.18.0-553.52.1.el8_10.x86_64-x86_64-with-glibc2.28
                program: -m verl.trainer.fsdp_sft_trainer
                python: CPython 3.10.18
                root: /gpfs/radev/project/zhuoran_yang/jh3439/simple-post-training
                slurm:
                    hint: nomultithread
                    job_id: "413333"
                startedAt: "2025-07-14T20:21:39.099484Z"
                writerId: 5zhpe6z6ijzaa17aujca5y8nixd2c31e
        m: []
        python_version: 3.10.18
        t:
            "1":
                - 1
                - 5
                - 11
                - 30
                - 41
                - 49
                - 50
                - 51
                - 53
                - 71
                - 98
                - 105
            "2":
                - 1
                - 5
                - 11
                - 30
                - 41
                - 49
                - 50
                - 51
                - 53
                - 71
                - 98
                - 105
            "3":
                - 13
                - 61
            "4": 3.10.18
            "5": 0.21.0
            "6": 4.51.1
            "12": 0.21.0
            "13": linux-x86_64
